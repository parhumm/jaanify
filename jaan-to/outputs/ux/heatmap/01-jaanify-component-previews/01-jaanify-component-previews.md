# Jaanify Component Previews — Predictive UX Audit

> Generated by jaan.to | 2026-02-07 | Skill: ux-heatmap-analyze

**Pages**: Dashboard, Task Input, Onboarding (3 components) | **Device**: Mobile-first (480px) | **Date Range**: Pre-implementation | **Page Views**: N/A (predictive audit)
**Files**: 01-component-preview-jaanify-dashboard.html, 02-component-preview-jaanify-task-input.html, 03-component-preview-jaanify-onboarding.html

---

## Action Summary

**Goal**: Predictive UX audit of 3 Jaanify component previews — attention flow, layout effectiveness, interaction patterns, and accessibility readiness. No heatmap CSV data available (pre-implementation); all findings are based on HTML structure, CSS analysis, and established UX pattern research.

- **Add a visible label or tooltip to the voice FAB** — The mic-only FAB has no text affordance; first-time users may not understand it triggers voice task capture [H]
- **Increase Reasoning Card Tier 1 tap target and visual prominence** — The primary differentiator (transparent AI reasoning) uses `font-size-xs` and subtle styling, risking low discovery rates [H]
- **Add explicit progress/time feedback to onboarding Step 1** — Users see "No account needed" but no indication of how many steps remain or how fast the flow is [H]
- **Ensure parsed result fields are keyboard-editable, not just tappable** — Edit buttons exist but no edit state is implemented; keyboard users and screen reader users will hit a dead end [H]
- **Reduce vertical distance between input and CTA in onboarding Step 1** — The `padding-top: 20vh` + `margin-top: 2rem` gap means the CTA may be below fold on smaller viewports [H]

---

## Findings & Actions

### CRITICAL: Reasoning Card — Jaanify's Core Differentiator Risks Being Overlooked

**Insight**: The 3-tier Reasoning Card is Jaanify's primary competitive advantage ("the AI that shows its work"), yet Tier 1 uses `font-size-xs` (~12px), secondary text color (`#6B7280`), and sits below the task metadata separated by a thin border. Users scanning the task list will focus on task titles, checkboxes, and time metadata — the reasoning text has lower visual hierarchy than the priority border and category tag. The PRD requires >30% expand rate (Tier 1 → Tier 2), but the current design may not achieve this without stronger visual cues.

**Do this**: Increase Tier 1 reasoning text to `font-size-sm`, use `color-primary` instead of secondary, and add a subtle background tint (e.g., `color-primary-subtle`) to differentiate it from plain metadata. Consider a pulsing or attention indicator on first 3 views.

| Metric | Value |
|--------|-------|
| ICE Score | 270 (I:9 C:6 E:5) |
| Confidence | 0.75 — Single-source [H] (predictive, no user data) |

**Evidence**:
- [H] Tier 1 uses `.reasoning-t1` with `font-size: var(--font-size-xs)` and `color: var(--color-text-secondary)` — identical visual weight to metadata like "~45 min" (dashboard.html:389-391)
- [H] Expand arrow (`.reasoning-t1__expand`) is 16px wide with muted color — low affordance for an interactive element (dashboard.html:405-411)
- [H] Research: Tier 1 expand rate target is >30% per PRD; Autodesk achieved +26% transparency scores with prominent AI Transparency Cards (synthesis report Theme 1)

---

### HIGH: Voice FAB Lacks Discoverable Affordance for First-Time Users

**Insight**: The floating action button (FAB) displays only a microphone SVG icon with no label text. While `aria-label="Capture task by voice"` aids screen readers, sighted users unfamiliar with the mic icon pattern may not associate it with voice-to-task creation — Jaanify's key 8-12 second flow. The FAB is the only voice entry point on the dashboard, yet it competes visually with the "What's on your mind?" inline add-task button which has text.

**Do this**: Add a "Speak" label below or beside the FAB icon on first 3 sessions (dismissable tooltip or permanent small label). Alternatively, animate the FAB with a brief pulse + tooltip on first dashboard load.

| Metric | Value |
|--------|-------|
| ICE Score | 210 (I:7 C:6 E:5) |
| Confidence | 0.75 — Single-source [H] (predictive) |

**Evidence**:
- [H] FAB has icon-only SVG, no text label; `.fab` class uses 56x56px circle with mic icon (dashboard.html:524-560)
- [H] In contrast, the inline add-task button includes visible text "What's on your mind?" alongside an icon (dashboard.html:852-857)
- [H] PRD target: >15% of all tasks created via voice. Without discoverable entry point, this metric is at risk

---

### HIGH: Onboarding Step 1 CTA May Fall Below Fold on Small Viewports

**Insight**: Step 1 of onboarding applies `padding-top: 20vh` plus the welcome mark (48px), title, subtitle, input, hint, and CTA button with `margin-top: 2rem`. On a 667px viewport (iPhone SE/8), the "Create with AI" CTA could be at ~460px+, potentially below fold. The 60-second onboarding promise depends on users immediately seeing and reaching the CTA.

**Do this**: Reduce `padding-top` from `20vh` to `12vh` on mobile, or use `min()` to cap vertical offset. Alternatively, pin the CTA to bottom of viewport on small screens.

| Metric | Value |
|--------|-------|
| ICE Score | 200 (I:8 C:5 E:5) |
| Confidence | 0.70 — Single-source [H] (requires device testing) |

**Evidence**:
- [H] `.step-1 { padding-top: 20vh; }` — on 667px screen, this is 133px before any content (onboarding.html:136-137)
- [H] Welcome mark (48px) + title (~48px) + subtitle (~24px) + spacing + input (~56px) + hint + CTA spacing = ~400px+ total content height
- [H] PRD: "first task in <30 seconds" requires zero scroll to reach CTA

---

### HIGH: Task Input Parsed Fields Have Edit Buttons Without Edit State

**Insight**: Each parsed field (deadline, category, priority, subtask) shows an edit pencil icon button, but no edit state is implemented in the HTML/JS. When a user taps "edit deadline", nothing happens. For keyboard/screen reader users, this creates a broken interaction promise — they tab to an interactive element that does nothing.

**Do this**: Either implement inline edit states (input replaces text on tap) or change edit buttons to navigational hints ("tap to edit" + link to modal). At minimum, add `aria-disabled="true"` and a visual disabled state until edit functionality is built.

| Metric | Value |
|--------|-------|
| ICE Score | 192 (I:8 C:6 E:4) |
| Confidence | 0.80 — Single-source [H] (directly observable in code) |

**Evidence**:
- [H] Four `.parsed-field__edit` buttons exist with `aria-label="Edit deadline"` etc. but no onclick handler or JS (task-input.html:556-615)
- [H] Screen reader will announce "Edit deadline, button" creating expectation of action — broken interaction pattern
- [H] WCAG 2.1 AA requires interactive elements to be operable; non-functional buttons violate 4.1.2 (Name, Role, Value)

---

### HIGH: Daily Plan Reasoning Is Passive — No Expand/Drill-Down Affordance

**Insight**: On the dashboard, the Daily Plan section includes reasoning text ("Plan based on: deadline urgency + dependency chains + your energy pattern") but the interaction affordance is weak. The element has `role="button"` and `tabindex="0"` and `aria-expanded="false"`, suggesting expandability, but there is no visible expand icon, no JS handler, and no Tier 2 content. Users see a clickable-looking element that does nothing.

**Do this**: Either wire up the daily plan reasoning to expand into a Tier 2 view (matching task card reasoning) or remove the `role="button"` and `aria-expanded` attributes to avoid misleading users.

| Metric | Value |
|--------|-------|
| ICE Score | 180 (I:6 C:8 E:5) |
| Confidence | 0.85 — Single-source [H] (directly observable: attributes promise interactivity without handler) |

**Evidence**:
- [H] `.daily-plan__reasoning` has `role="button" tabindex="0" aria-expanded="false"` but no onclick, no JS event listener, no expandable content below it (dashboard.html:665-671)
- [H] Task card reasoning cards DO have `onclick="toggleReasoning(this)"` and Tier 2 content — inconsistency in pattern (dashboard.html:694)
- [H] Screen reader announces "View plan reasoning, button, collapsed" — implies expandable content that doesn't exist

---

### MEDIUM: Onboarding Step 3 Uses Placeholder Tasks That May Confuse Users

**Insight**: Step 3 "Your Plan" shows the user's task at position #1 (good), but positions #2 and #3 are placeholder ("Add more tasks to see the full plan" and "Your next task goes here..."). The #3 item uses `opacity: 0.5` and muted color. While this communicates incompleteness, users may interpret the plan as pre-populated with irrelevant tasks or feel the AI isn't delivering on its promise of intelligent planning.

**Do this**: Replace placeholder text with contextually relevant suggestions based on the user's first task category. E.g., if task was "Call Sarah about proposal", suggest "Follow up on proposal email" and "Prepare meeting notes" as ghost suggestions.

| Metric | Value |
|--------|-------|
| ICE Score | 120 (I:6 C:5 E:4) |
| Confidence | 0.70 — Single-source [H] (predictive) |

**Evidence**:
- [H] Plan task #2: "Add more tasks to see the full plan" — meta-instruction, not a task example (onboarding.html:752-755)
- [H] Plan task #3 uses inline `style="opacity: 0.5;"` and `style="color: var(--color-text-muted);"` — inconsistent with class-based styling (onboarding.html:756-761)
- [H] This is the user's first experience of Jaanify's AI planning — first impression sets trust baseline

---

### MEDIUM: Suggestion Chips on Task Input Lack Keyboard Accessibility

**Insight**: The 4 suggestion chips ("Call...", "Remind me...", "Review...", "Buy...") use `role="listitem"` inside a `role="list"` container. However, `role="listitem"` on a `<button>` element creates a semantic conflict — buttons should not be listitems. Screen readers may announce these confusingly. Additionally, the chips have no visible focus indicator beyond the generic `box-shadow: var(--shadow-focus)`.

**Do this**: Remove `role="listitem"` from buttons and `role="list"` from container. Use a `<nav aria-label="Quick suggestions">` with plain buttons instead. The focus ring is adequate via `box-shadow`.

| Metric | Value |
|--------|-------|
| ICE Score | 96 (I:4 C:8 E:3) |
| Confidence | 0.85 — Single-source [H] (directly observable ARIA misuse) |

**Evidence**:
- [H] `<div class="suggestions" role="list">` containing `<button class="suggestion-chip" role="listitem">` — invalid role on interactive element (task-input.html:502-507)
- [H] WCAG 4.1.2: elements must have roles compatible with their base semantics; `<button>` has implicit `role="button"`

---

### LOW: Design Token Consistency — Onboarding Has Extra Token Not in Other Components

**Insight**: The onboarding component defines `--font-size-3xl` and `--transition-entrance` tokens that don't exist in the dashboard or task-input components. While this works in isolation, in a shared design system these inconsistencies can cause rendering issues or require separate token management.

**Do this**: When consolidating into the shared TailwindCSS v4 design system, ensure all tokens are defined in one place and all three components reference the same token set.

| Metric | Value |
|--------|-------|
| ICE Score | 48 (I:3 C:8 E:2) |
| Confidence | 0.85 — Single-source [H] (directly observable) |

**Evidence**:
- [H] Onboarding defines `--font-size-3xl: clamp(1.75rem, 1.5rem + 1.25vw, 2.25rem)` (onboarding.html:36) and `--transition-entrance: 500ms cubic-bezier(0.16, 1, 0.3, 1)` (onboarding.html:59) — neither exists in dashboard.html or task-input.html
- [H] All three components duplicate the full design token block (~60 CSS custom properties) rather than importing from a shared source

---

## Test Ideas

Experiments derived from findings above.

### A/B Tests

1. **Reasoning Card visual weight** — Test current `font-size-xs` + secondary color vs `font-size-sm` + primary color for Tier 1 text. Measure: Tier 1 → Tier 2 expand rate. Validates Finding #1.
2. **Voice FAB label vs icon-only** — Test FAB with "Speak" label vs icon-only. Measure: voice task creation rate (% of all tasks). Validates Finding #2.
3. **Onboarding CTA position** — Test `padding-top: 20vh` vs `12vh` for Step 1. Measure: time-to-first-task-creation, CTA click rate without scrolling. Validates Finding #3.
4. **Placeholder vs contextual ghost tasks** — Test generic "Add more tasks" placeholder vs AI-generated contextual suggestions in onboarding Step 3. Measure: onboarding completion rate (Step 3 → Step 4). Validates Finding #6.

### UX Research

1. **5-user usability test**: "Create a task using only your voice" — Can users discover and use the FAB without prompting? Explores Finding #2.
2. **Think-aloud protocol**: "Tell me what the green text below this task means" — Do users notice and understand Tier 1 reasoning? Explores Finding #1.
3. **First-click test**: Show onboarding Step 1 screenshot — Where do users click first? Is the CTA discoverable without scrolling? Explores Finding #3.
4. **Accessibility audit with screen reader**: Navigate all 3 flows with VoiceOver — Identify broken interaction patterns, ARIA misuse. Explores Findings #4, #5, #7.

---

## Element Mapping

| Component | Element | Type | Predicted Attention | Notes |
|-----------|---------|------|-------------------|-------|
| Dashboard | Header greeting | Text | HIGH | First read point, personalized |
| Dashboard | Stats row (5/8, 3h, 7) | Data | HIGH | Numbers draw eye, compact format |
| Dashboard | Daily Plan card | Card | HIGH | Green background, prominent position |
| Dashboard | Task card titles | Text | HIGH | Primary scan targets in list |
| Dashboard | Task card checkboxes | Interactive | HIGH | Primary interaction target |
| Dashboard | Reasoning T1 text | Text | LOW-MEDIUM | Small, secondary color, below fold of each card |
| Dashboard | Reasoning T1 expand arrow | Interactive | LOW | 16px, muted, no label |
| Dashboard | Voice FAB | Interactive | MEDIUM | Fixed position, green, but no label |
| Dashboard | "What's on your mind?" add-task | Interactive | MEDIUM | Dashed border, has text |
| Task Input | Textarea | Interactive | HIGH | Full-width, large font, auto-focus expected |
| Task Input | Suggestion chips | Interactive | MEDIUM | Above input, small but grouped |
| Task Input | Voice mic button | Interactive | LOW-MEDIUM | 36px, corner position, no label |
| Task Input | Parsed result card | Card | HIGH | Shadow, border, slide-in animation |
| Task Input | Edit pencil buttons | Interactive | MEDIUM | Present but non-functional |
| Task Input | Save/Cancel buttons | Interactive | HIGH | Primary CTA, appears after parse |
| Onboarding S1 | Welcome title | Text | HIGH | Largest text on page |
| Onboarding S1 | Input field | Interactive | HIGH | Only interactive element, auto-focus |
| Onboarding S1 | "Create with AI" CTA | Interactive | MEDIUM-HIGH | Appears on input, may be below fold |
| Onboarding S2 | Enriched task card | Card | HIGH | Shadow, center content |
| Onboarding S2 | Reasoning Card (green) | Card | HIGH | Distinct green background, "aha moment" |
| Onboarding S3 | Plan task #1 (highlighted) | Card | HIGH | Green background, numbered rank |
| Onboarding S3 | Plan task #2-3 (placeholder) | Card | LOW | Reduced opacity, generic text |
| Onboarding S4 | Google sign-in button | Interactive | HIGH | Large, centered, logo |
| Onboarding S4 | "Skip for now" link | Interactive | MEDIUM | Text-only, below primary CTA |

---

## Cross-Component Patterns

**Consistent strengths across all 3 components:**
- Shared design token system (warm sage/cream palette, DM Sans, 8px spacing)
- Dark mode support via `prefers-color-scheme: dark` media query
- Reduced motion support via `prefers-reduced-motion: reduce`
- Screen reader utilities (`.sr-only` class, `aria-live="polite"` regions)
- Focus-visible styles with consistent `box-shadow: var(--shadow-focus)`
- Mobile-first responsive breakpoints (480px → 768px → 1024px)

**Consistent weaknesses across components:**
- Token duplication (each HTML file duplicates ~60 CSS custom properties)
- No shared JS utility layer (each file has inline `<script>`)
- ARIA patterns vary: dashboard uses `role="button"` with `onclick`, task-input uses semantic `<button>`, onboarding mixes both

---

> **Limitations**: Pre-implementation predictive audit — no real user interaction data (heatmap CSV, click coordinates, session recordings). All findings derive from HTML/CSS/JS structure analysis only. Maximum confidence capped at 0.85 for vision-only findings per LEARN.md guidelines. Actual user behavior may differ significantly from predicted attention patterns. Findings should be validated with real heatmap data post-launch.
> **Method**: Single-source HTML analysis | Confidence threshold: 0.70 | Prioritization: ICE scoring (Impact x Confidence x Ease)

---

> Generated by jaan.to ux-heatmap-analyze | 2026-02-07

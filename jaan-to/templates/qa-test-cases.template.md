# Test Cases: {{title}}

> Generated by jaan.to | {{date}}

---

## Executive Summary

{{executive_summary}}

---

## Metadata

| Field | Value |
|-------|-------|
| Acceptance Criteria | {{ac_count}} |
| Total Test Cases | {{total_tests}} |
| Test Breakdown | Positive: {{positive_count}} ({{positive_pct}}%), Negative: {{negative_count}} ({{negative_pct}}%), Edge: {{edge_count}} ({{edge_pct}}%) |
| Edge Case Categories | Empty/Null: {{empty_count}}, Boundary: {{boundary_count}}, Error: {{error_count}}, Concurrent: {{concurrent_count}}, State: {{state_count}} |
| Format | BDD/Gherkin |
| Generated | {{date}} |
| Skill | qa:test-cases |
| Traceability | {{requirement_ids}} |

---

## Acceptance Criteria Coverage

| # | Acceptance Criterion | Test Count | Coverage |
|---|---------------------|------------|----------|
{{ac_coverage_rows}}

---

## BDD/Gherkin Test Scenarios

### Feature: {{feature_name}}

As a {{role}}
I want {{goal}}
So that {{benefit}}

#### Background

```gherkin
{{background_steps}}
```

---

#### Positive Tests

{{positive_scenarios}}

---

#### Negative Tests

{{negative_scenarios}}

---

#### Boundary Tests

{{boundary_scenarios}}

---

#### Edge Case Tests

{{edge_scenarios}}

---

## ISTQB Conversion Notes

For teams using traditional test management tools (Xray, TestRail, Azure DevOps):

### Field Mapping

| BDD Element | ISTQB Equivalent | Conversion |
|-------------|------------------|------------|
| Feature | Test Suite | Groups related scenarios |
| Background | Shared Preconditions | Apply to all test cases |
| Given | Preconditions | Initial system state |
| When | Test Steps/Actions | User actions triggering behavior |
| Then | Expected Results | Observable, verifiable outcomes |
| @tags | Test Attributes | Priority, type, traceability |
| Scenario Outline + Examples | Parameterized Test Case | Data-driven execution |

### Example Conversion

**BDD Scenario:**
```gherkin
@smoke @positive @priority-critical @REQ-AUTH-001
Scenario: Successful login with valid credentials
  Given I am on the login page
  When I enter "test@example.com" in the email field
  And I enter "ValidP@ss123!" in the password field
  And I click the "Login" button
  Then I should be redirected to the dashboard within 3 seconds
  And I should see "Welcome, Test User" in the header
```

**ISTQB Format:**

| Field | Value |
|-------|-------|
| Test Case ID | TC-AUTH-001 |
| Title | Successful login with valid credentials |
| Priority | Critical |
| Traceability | REQ-AUTH-001 |
| Tags | @smoke, @positive, @regression |
| **Preconditions** | User account exists: test@example.com<br>Account is not locked<br>Browser: Login page loaded |
| **Step 1** | Action: Navigate to login page<br>Data: https://app.example.com/login<br>Expected: Login form displays |
| **Step 2** | Action: Enter email<br>Data: test@example.com<br>Expected: Email field populated |
| **Step 3** | Action: Enter password<br>Data: ValidP@ss123!<br>Expected: Password field masked |
| **Step 4** | Action: Click Login button<br>Data: -<br>Expected: Redirected to dashboard <3s, "Welcome, Test User" displays |

### Export Formats

**CSV for Xray/TestRail** (semicolon-delimited):
```csv
TCID;Summary;Preconditions;Step;Action;Data;Expected Result;Tags
TC-001;Login Test;User exists;1;Navigate;/login;Form displays;smoke,regression
TC-001;Login Test;User exists;2;Enter email;test@example.com;Email populated;smoke,regression
```

**JSON for API Import:**
```json
{
  "id": "TC-AUTH-001",
  "title": "Successful login with valid credentials",
  "priority": "critical",
  "tags": ["smoke", "regression"],
  "preconditions": ["User exists", "Account not locked"],
  "steps": [
    {"action": "Enter email", "data": "test@example.com", "expected": "Email populated"},
    {"action": "Click Login", "data": "", "expected": "Dashboard displays"}
  ]
}
```

---

## Traceability Matrix

| Requirement | Acceptance Criterion | Test Cases | Count |
|-------------|---------------------|------------|-------|
{{traceability_rows}}

---

## Test Execution Guidelines

### Environment Requirements

{{environment_requirements}}

### Test Data Setup

{{test_data_setup}}

### Shared Preconditions

{{shared_preconditions}}

### Execution Order

Tests are **independent** and can be executed in any order. However, for optimal results:

1. **Smoke suite first**: Run tests tagged @smoke to verify critical paths
2. **Regression suite**: Run all tests tagged @regression
3. **Priority-based**: Execute @priority-critical, then @priority-high, then @priority-medium/low

### Test Data Guidelines

All test cases use **concrete data values** (not placeholders):

- **Emails**: test@example.com, invalid@test.com, user+test@example.com
- **Passwords**: ValidP@ss123!, weak, tooshort1, 123456
- **Dates**: 2024-01-15, 2024-12-31, 2024-02-29
- **Numbers**: 0, 1, 50, 99, 100, 101, -1
- **URLs**: https://app.example.com/login
- **Names**: "John Doe", "Test User"

These values are **safe for test environments** and should be created/cleaned up per test run.

---

## Quality Checklist

See auxiliary file for quality validation:
**{{quality_checklist_filename}}**

Includes:
- 10-point peer review checklist
- Anti-patterns to avoid
- Quality scoring rubric (100-point)
- Coverage sufficiency analysis

**Quick Quality Check:**
- ✅ All tests map to acceptance criteria
- ✅ All steps use concrete values (no placeholders)
- ✅ All scenarios have explicit preconditions
- ✅ Expected results are measurable (thresholds, exact text)
- ✅ Traceability tags present (@REQ-{id})
- ✅ Coverage distribution: 30% positive, 40% negative, 30% edge
- ✅ All 5 edge case categories represented

---

## Appendix

### Test Design Techniques Applied

- **Equivalence Partitioning**: Input domains divided into valid/invalid partitions with representative values
- **Boundary Value Analysis**: Min/max boundaries tested with 3-value BVA (boundary ± 1)
- **Edge Case Taxonomy**: 5 priority categories based on production defect frequency

### Research Foundation

Test case generation follows ISTQB standards and IEEE 829 specifications:
- ISTQB Foundation Level Syllabus v4.0
- IEEE 829-2008 Standard for Software and System Test Documentation
- BDD/Gherkin best practices (cucumber.io)

### Coverage Analysis

**Industry Standard**: 70-80% code coverage

**Our Coverage** (estimated based on test count and AC):
- **Positive scenarios**: {{positive_pct}}% (target: 30%)
- **Negative scenarios**: {{negative_pct}}% (target: 40%)
- **Edge cases**: {{edge_pct}}% (target: 30%)

**Edge Case Distribution**:
1. Empty/Null States: {{empty_count}} tests (32% of bugs)
2. Boundary Values: {{boundary_count}} tests (28% of bugs)
3. Error Conditions: {{error_count}} tests (22% of bugs)
4. Concurrent Operations: {{concurrent_count}} tests (12% of bugs)
5. State Transitions: {{state_count}} tests (6% of bugs)

### Metadata

| Field | Value |
|-------|-------|
| Generated | {{date}} |
| Skill | qa:test-cases |
| Version | 1.0 |
| Format | BDD/Gherkin |
| Research | ISTQB, IEEE 829, BDD best practices |
| Techniques | Equivalence Partitioning, BVA, Edge Case Taxonomy |
| AI Failure Mitigations | 5 failure modes addressed (vague steps, missing preconditions, placeholders, over-specification, missing negative tests) |
